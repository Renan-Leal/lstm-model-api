# ğŸ“ˆ LSTM Model API â€“ Stock Price Prediction

This project implements an **LSTM (Long Short-Term Memory) model** for **stock closing price prediction**, exposing the trained model through a **RESTful API** built with **FastAPI**.  
The solution follows good **data science**, **machine learning**, and **MLOps** practices, including containerization with **Docker**.

---

## ğŸ§  Project Overview

The objective of this project is to:

- Train an LSTM model to predict the **next closing price** of a stock based on historical data
- Evaluate different model configurations and select the best-performing one
- Persist the trained model and preprocessing artifacts
- Expose predictions through a scalable and reusable **API**
- Make the solution reproducible using **Docker**

This project was developed as part of a **Machine Learning / Deep Learning technical challenge**, focusing on **time series forecasting**.

---

## ğŸ—‚ï¸ Project Structure

```
lstm-model-api/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ docker-compose-dev.yml
â”‚   â”œâ”€â”€ docker-compose-prod.yml
â”‚   â””â”€â”€ docker-compose.dozzle.yml
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ down-dev.sh
â”‚   â”œâ”€â”€ down-prod.sh
â”‚   â”œâ”€â”€ run-dev.sh
â”‚   â””â”€â”€ run-prod.sh
â”‚
â”œâ”€â”€ app.py                     # FastAPI application
â”œâ”€â”€ modelo_lstm.keras          # Trained LSTM model (Keras format)
â”œâ”€â”€ scaler.pkl                 # MinMaxScaler used during training
â”‚
â”œâ”€â”€ tech_challenge_lstm.ipynb  # Notebook with data analysis, training and evaluation
â”‚
â”œâ”€â”€ Dockerfile                 # Docker image configuration
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # Project documentation
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ .dockerignore
```

---

## ğŸ“Š Data Science & Modeling

### Model Type

- **LSTM (Long Short-Term Memory)**
- Suitable for sequential and time series data

### Input Data

- Historical **closing prices**
- Fixed sliding window (`window_size = 60`)

### Target

- **Next-day closing price**

### Preprocessing

- MinMax normalization using `MinMaxScaler`
- Sliding window sequence creation
- Same preprocessing pipeline reused in inference (API)

---

## ğŸ“‰ Model Evaluation

Multiple configurations were tested, including:

- Different window sizes
- Increased model capacity
- Different loss functions (MSE vs MAE)

### Best Configuration Selected

- **Window size:** 90
- **Loss function:** MAE
- **Increased model capacity**

This configuration achieved the lowest error values (MAE, RMSE, and MAPE), indicating better generalization and robustness.

---

## ğŸš€ API Description

The API is built using **FastAPI** and exposes the trained LSTM model for inference.

### Available Endpoints

#### `POST /predict`

Predicts the **next closing price** based on the last 60 closing prices.

**Input**

```json
{
  "last_60_prices": [50.1, 50.2, "...", 51.3]
}
```

**Output**

```json
{
  "predicted_close_price": 51.68
}
```

---

#### `GET /health`

Health check endpoint to verify API and model availability.

---

#### `GET /model-info`

Returns metadata and configuration details about the trained model.

---

#### `POST /explain`

Provides a **simplified explanation** of the prediction based on recent trends and volatility.

---

## ğŸ³ Running with Docker

### Build the image

```bash
docker build -t model-lstm-api .
```

### Run with Docker Compose

```bash
docker-compose up
```

The API will be available at:

```
http://localhost:8000/docs
```

---

## ğŸ§ª Interactive Documentation

FastAPI automatically generates interactive documentation using Swagger:

```
http://localhost:8000/docs
```

---

## ğŸ› ï¸ Technologies Used

- Python 3.10+
- TensorFlow / Keras
- NumPy
- Scikit-learn
- FastAPI
- Uvicorn
- Docker & Docker Compose

---

## ğŸ“Œ Key Highlights

- End-to-end ML pipeline (training â†’ evaluation â†’ deployment)
- Consistent preprocessing between training and inference
- REST API ready for integration
- Dockerized for reproducibility and deployment
- Clear separation between data science and production layers

---

## ğŸ—ï¸ Architecture Diagram

### GIF

### ![Gif](diagrams/arch-diagram.gif)

### PNG

### ![Png](diagrams/arch-diagram.png)

## ğŸ“„ License

This project is for **educational and demonstrative purposes**.
